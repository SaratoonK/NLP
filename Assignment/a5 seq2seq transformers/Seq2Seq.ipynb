{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f6b95d-cf41-4898-b8b0-935da50e380a",
   "metadata": {},
   "source": [
    "## What is a Summary?\n",
    "A summary is a condensed version of an original text, usually a full article or book. Summaries are usually around a paragraph long, and may even be a few paragraphs long depending on the length of the work being condensed.\n",
    "\n",
    "Summaries are used in variety of situations. For example, you might want to summarize only the main points of a meeting with a co-worker because you're running late for another meeting. Or, let's say you want to introduce a complex design idea. You could begin by summarizing what your design would accomplish, to give key people an overall sense of your plan without overwhelming them. Students might summarize an article for a class, or when preparing and writing research papers, annotated bibliographies and essays. Abstracts and legal brief are also types of summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80d252-76a6-4215-879e-b1eb5b2f0452",
   "metadata": {},
   "source": [
    "And the \"summary\" itself has some varieties and approaches.\n",
    "\n",
    "#### Types of summary\n",
    "\n",
    "* **Indicative summary** <br>\n",
    "It looks like a summary of the book. This summary describes what kinds of the story, but not tell all of the stories especially its ends (so indicative summary has only partial information).\n",
    "* **Informative summary** <br>\n",
    "In contrast to the indicative summary, the informative summary includes full information of the document.\n",
    "* **Keyword summary** <br>\n",
    "Not the text, but the words or phrases from the input document.\n",
    "* **Headline summary** <br>\n",
    "Only one line summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa346f5-7037-4360-b361-8677eb649e53",
   "metadata": {},
   "source": [
    "## Basic Approach\n",
    "\n",
    "There are mainly two ways to make the summary. Extractive and Abstractive. In short, in extractive summarization sentences are chosen from the article(s) given as input, whereas in abstractive summarization sentences may be generated or a new representation of the article(s) may be output.\n",
    "\n",
    "### Extractive\n",
    "\n",
    "* Select relevant phrases of the input document and concatenate them to form a summary (like \"copy-and-paste\").\n",
    "  * Pros: They are quite robust since they use existing natural-language phrases that are taken straight from the input.\n",
    "  * Cons: But they lack in flexibility since they cannot use novel words or connectors. They also cannot paraphrase like people sometimes do.\n",
    "\n",
    "\n",
    "### Abstractive\n",
    "\n",
    "* Generate a summary that keeps original intent. It's just like humans do.\n",
    "  * Pros: They can use words that were not in the original input. It enables to make more fluent and natural summaries.\n",
    "  * Cons: But it is also a much harder problem as you now require the model to generate coherent phrases and connectors.\n",
    "\n",
    "Extractive & Abstractive is not conflicting ways. You can use both to generate the summary. And there are a way collaborate with human.\n",
    "\n",
    "* Aided Summarization\n",
    "  * Combines automatic methods with human input.\n",
    "  * Computer suggests important information from the document, and the human decide to use it or not. It uses information retrieval, and text mining way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60c2ef-e43d-4fb7-a515-f3f930972a0d",
   "metadata": {},
   "source": [
    "The beginning of the abstractive summarization, [Banko et al. (2000)](http://www.anthology.aclweb.org/P/P00/P00-1041.pdf) suggest to use machine translatation model to abstractive summarization model. As like the machine translation model converts a source language text to a target one, the summarization system converts a source document to a target summary.\n",
    "\n",
    "Nowadays, encoder-decoder model that is one of the neural network models is mainly used in machine translation. So this model is also widely used in abstractive summarization model. [The summarization model that used encoder-decoder model first](http://www.aclweb.org/anthology/N16-1012) achieved state-of-the-art on the two sentence-level summarization dataset, DUC-2004 and Gigaword.\n",
    "\n",
    "If you want to try the encoder-decoder summarization model, tensorflow offers basic model.\n",
    "\n",
    "* [Text summarization with TensorFlow](https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html)\n",
    "\n",
    "#### Encoder-Decoder Model\n",
    "\n",
    "The encoder-decoder model is composed of encoder and decoder like its name. The encoder converts an input document to a latent representation (vector), and the decoder generates a summary by using it.\n",
    "\n",
    "![encoder_decoder.png](./images/encoder_decoder.png)  \n",
    "* from [Computer, respond to this email](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4410c3-2803-46a2-9b1e-518806dadac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "But the encoder-decoder model is not the silver bullet. There are many remaining issues are there. \n",
    "\n",
    "* How to set the focus on the important sentence, keyword.\n",
    "* How to handle the novel/rare (but important) word in source document.\n",
    "* How to handle the long document.\n",
    "* Want to make more human-readable summary.\n",
    "* Want to use large vocabulary.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
