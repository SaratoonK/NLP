{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "## Word2Vec (Negative Sampling)\n",
        "\n",
        "Let's work on negative-sampling based implementation of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'cat', 'dog', 'apple', 'banana']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fruit': 0, 'animal': 1, 'cat': 2, 'dog': 3, 'apple': 4, 'banana': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'cat', 'dog', 'apple', 'banana', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence):\n",
        "    \n",
        "    # Make skip gram of one size window\n",
        "    skip_grams = []\n",
        "    # loop each word sequence\n",
        "    # we starts from 1 because 0 has no context\n",
        "    # we stop at second last for the same reason\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[3]\n",
            " [1]]\n",
            "Target:  [[1]\n",
            " [3]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "print(\"Input: \",  input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2, 1), (2, 1))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Negative Sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unigram distribution\n",
        "\n",
        "$$P(w)=U(w)^{3/4}/Z$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "Z = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter(flatten(corpus))\n",
        "num_total_words = sum([c for w, c in word_count.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count[',']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "unigram_table = []\n",
        "\n",
        "for vo in vocab:\n",
        "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'fruit': 260,\n",
              "         'animal': 260,\n",
              "         'cat': 260,\n",
              "         'dog': 260,\n",
              "         'apple': 260,\n",
              "         'banana': 260})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(unigram_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Negative Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.size(0)\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):\n",
        "        nsample = []\n",
        "        target_index = targets[i].item()\n",
        "        while len(nsample) < k: # num of sampling\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
        "    \n",
        "    return torch.cat(neg_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_batch  = torch.Tensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5, 0, 0],\n",
              "        [5, 0, 4]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_neg = 3\n",
        "negative_sampling(target_batch, unigram_table, num_neg)\n",
        "\n",
        "#{'grapes': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'ice': 4, 'orange': 5, 'dog': 6, 'monkey': 7, 'conda': 8, 'fruit': 9, 'banana': 10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "                    \n",
        "    def forward(self, center_words, target_words, negative_words):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
        "        \n",
        "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        negative_score = torch.sum(neg_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2), 1).view(neg_embeds.size(0), -1) # BxK -> Bx1\n",
        "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1] = [batch_size, k] ==sum==> [batch_size, 1]\n",
        "        \n",
        "        loss = self.logsigmoid(positive_score) + self.logsigmoid(negative_score)\n",
        "        \n",
        "        return -torch.mean(loss)\n",
        "    \n",
        "    def prediction(self, inputs):\n",
        "        embeds = self.embedding_v(inputs)\n",
        "        \n",
        "        return embeds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 2 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
        "num_neg        = 10 # num of negative sampling\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 0.712312 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 1.736569 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 3.781283 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 0.213942 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 0.468755 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "    \n",
        "    #input_batch: [batch_size, 1]\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    \n",
        "    #target_batch: [batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "    \n",
        "    #negs_batch:   [batch_size, num_neg]\n",
        "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    loss = model(input_batch, target_batch, negs_batch)\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'cat', 'dog', 'apple', 'banana', '<UNK>']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-1.1799, -0.0512]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[-0.0018,  1.7162]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.8325, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAEWCAYAAACXLsbnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwyklEQVR4nO3deVyU5d4G8GuGnWBAZFcUFwQUV0wENTV4w1Sy5T3H0uMu5lFLJVMMtzTFFU2zTDuEpzTM82p51EhFLRfSRDAXRMEFU8ANGEBjm/v9w8OcRgYEnIUHr+/n83xy7ud+nvndkDOX97PJhBACRERERBIjN3YBRERERPXBEENERESSxBBDREREksQQQ0RERJLEEENERESSxBBDREREksQQQ0RERJLEEENERESSxBBDREREksQQQzWKi4uDvb29scsgIiKqgiGGiIiIJMnU2AXomkqlwq1bt2BrawuZTGbsciTv4cOHAAClUmnkSoiISN+EECgsLIS7uzvkcgnMcwg9+umnn8TgwYOFm5ubACB27tz5xG0OHTokunbtKszNzUWbNm3El19+Waf3vHHjhgDAhQsXLly4cKnncuPGjfp98RuYXmdiiouL0blzZ4wdOxavv/76E/tfvXoVgwYNwsSJE7FlyxYkJiZi/PjxcHNzQ2hoaK3e09bWFgBw48YNKBSKp6q/ofv+++8hk8nQoUMHFBcXY8mSJcjKysLRo0dx48YNdOrUCc2aNUN0dDR8fHzwySefYOfOnfjtt9/g4OCAI0eOYPDgwfD29sbSpUvh4uKChQsX4sKFCzh9+jTMzMywZcsWzJ49G1lZWQCA48ePY+jQoVi2bBkCAwNx9epVTJ06FcOHD0dkZKSRfyJERPQ0lEolPDw81N+lDZ6h0hLw5JmYmTNnig4dOmi0DR06VISGhtb6fQoKCgQAUVBQUJ8yJe3OnTsCgDh79qy4evWqACCWLl2qXl9WViaaN28uli1bJoR4NOsFQMTHx6v73Lt3T1hZWYlt27YJIYT48ssvhZ2dnXp9cHCwWLJkicb7fvXVV8LNzU2PIyMiIkOQ2ndogzrglZSUhJCQEI220NBQJCUlVbtNSUkJlEqlxvKsuHz5Mt566y20bt0aCoUCnp6eAKCeNQGAwMBA9Z9NTU3RvXt3pKWlaeznz30cHBzg7e1dpU+lM2fOYOHChbCxsVEv4eHhyM7OxoMHD3Q4OiIiopo1qBN7c3Jy4OLiotHm4uICpVKJhw8fwsrKqso20dHR+PDDDw1VYoMSFhaGli1bYtOmTXB3d4dKpYKfnx9KS0v19p5FRUX48MMPtR4etLS01Nv7EhERPa5BzcTUx+zZs1FQUKBebty4YeySDOLevXtIT0/HnDlzEBwcDF9fX+Tl5VXp98svv6j/XF5ejuTkZPj6+lbbJy8vD5cuXarSp1K3bt2Qnp6Otm3bVlkkcSY7ERE1Gg1qJsbV1RW5ubkabbm5uVAoFFpnYQDAwsICFhYWhijPYFQqgezL+ShWluA5hQXcvOwhl2teLt6kSRM0bdoUGzduhJubG7KysrSeWLt+/Xp4eXnB19cXq1evRl5eHsaOHavRZ+HChWjatClcXFwQFRUFR0dHvPrqq1prmzdvHgYPHowWLVrgf//3fyGXy3HmzBmcO3cOH330kc5+BkRERE/SoEJMYGAg9u7dq9G2f/9+jXM2GrvMlNs4su0yivNL1G3P2Vugz1AvtOnqrG6Ty+WIj4/Hu+++Cz8/P3h7e2Pt2rXo16+fxv6WLl2KpUuXIjU1FW3btsWuXbvg6OhYpc/UqVNx+fJldOnSBf/+979hbm6utb7Q0FDs3r0bCxcuxLJly2BmZgYfHx+MHz9edz8EIiKiWpAJIYS+dl5UVISMjAwAQNeuXRETE4P+/fvDwcEBLVq0wOzZs3Hz5k3885//BPDoEms/Pz9MnjwZY8eOxcGDB/Huu+9iz549tb7EWqlUws7ODgUFBZK7xDoz5TYSPj9X7foBb/tpBJmaXLt2Da1atUJKSgq6dOmitc/hw4fRv39/5OXl8dECREQkue9QvZ7EcOrUKXTt2hVdu3YFAERERKBr166YN28eACA7O1vjSppWrVphz5492L9/Pzp37oxVq1bhiy++qHWAkTKVSuDItss19jn67WWoVHrLnERERJKi18NJ/fr1Q00TPXFxcVq3SUlJ0WNV+iOEwNtvv41//etfyMvLq3EW5HHZl/PVh5Au3UrF2n+/h+Wjv4e1hY26T1FeCbIv56OZdxN9lE9ERCQpvJxEhxISEhAXF4fdu3cjOzsbfn5+Wvtdu3YNMpkMqamp6rZi5aMAs2ZXBFKvHMGSEdthZf4c5m0ZhimfB+O9fwzS6Ddt2jSN818WLFigEZg8PT3x888/o1+/fpg2bZrWMFkZMnkoiYiIpIghRocyMzPh5uaGoKAguLq6wtRUc6IrNzcXRUVFWrd9TvHfK6zkMjkU1g7qB1iayE1RVlFapV9NKs8jioiIwJo1ayCTyXDnzh388ccf9RkaERFRg8MQoyOjR4/GO++8g6ysLMhkMnh6eqJfv36YNGkShgwZAgsLC7i5ueHnn39Gq1atNLbNz89Hcx8H3FCef/S6+A6mfB6MByVFKKsoRYWqHCqhwpTPg9HcxwELFiyosZatW7fi9ddfx/Lly9XnHwHA3r174ebmhokTJ9Z4F2QiIiIpYIjRkY8//hgLFy5E8+bNkZ2djc2bNyMzMxMbNmzAvn378MYbb2Dr1q1o3759tfvo2L95lTZTEzN08uwFE7kp2rZuh5s3b2LGjBnV7mP9+vUYM2YMYmNjMWXKFI11w4cPx9dff428vDy8+OKL8Pb2xpIlS56ZGwQSEVHjwhCjI3Z2dpDL5SguLsbAgQPx0ksv4eHDh/D09ERBQQG2bt2KN998s8Z9NPNqAgf352Bi9t9fiwwyWFlZwdLKErl3spGYmAgbGxut26elpWHKlCn47LPPMHz48CrrTU1NMWjQIGzbtg05OTmYMWMGEhIS0KpVK4SEhOCrr77Cw4cPn+4HQUREZCAMMTp05MgR5OXlwcbGBhkZGfDz80NwcHC1N47TxsrGDC39mgIA+o/whrXCHK06O8LU1AQzZszAvHnzqn02UvPmzdGtWzesWLEC2dnZNb6PnZ0dwsPD8fPPP+P48eO4evUqRo4ciR9//LH2AyYiIjIihhgdCgwMhJ2dHXJyctChQwdcvHgR9+/fh0qlUvf58/OFCgoKAABlZWXqtvz8fPVMS9tuLjAxk6tP8I2IiMDDhw/x6aefan1/W1tbHDhwAM899xz69+9fY5D5448/sH37doSFhaF3795wdHTEp59+iuDg4Pr/AIiIiAyIIUaH7OzsYG9vj0uXLiEhIQFyuRy7d+9Gy5YtERkZifPnz8PJyQkAoFAokJycDADqS62Li4uRkZGB5s01z40xMTFBRUUFbGxsMHfuXCxevBiFhYVaa2jSpAkOHDgAhUKBfv364datW+p1QggcOXIE4eHhcHV1RUREBPz8/PDbb7/hxIkT+Pvf/w5bW1s9/GSIiIh0jyHmCcrLVTh9JAs/f5+O00eyUF6uevJGAIKCgtCuXTuEh4djxYoVSE1NRefOnZGRkYGePXvCwcEBixYtwpw5c9Qn6i5evBhOTk544YUXNPbl4OCAoqIiJCYm4vXXX4dCocDWrVurfW97e3vs378fTZo00QgyX3/9NUJDQ/HgwQN8++23uH79OqKjo+Hj41PPnw4REZHxNKgHQDY0x/dehvWRbDgLGSqfWHRu7zU86OOGoIFetdqHqakp3nzzTbz55pu4desWbGxsEBsbi7Fjx+LmzZtYtWqV+kZ0lpaWOHToEK5du6axj1atWmHixIkYOnQo7t27h9dffx1Xrlyp8X3t7Oywb98+DBgwAH379sXhw4cRHByMnJwcSTwPg4iI6En0+gBIY9DVw6uO770Mj5+zIQDIIVO3qyAgA3DjhdoHGSIiIingAyAbgfJyFayPVA0w+M9rAcD6SHatDy0RERGR7jHEaPFb0u9wFLIqAaaSHDI4Chl+S/rdwJURERFRJYYYLYru1+6Gb7XtR0RERLrHEKOFjYOVTvsRERGR7jHEaNEpsDnuygRU0H7OswoCd2UCnQKrPuuIiIiIDIMhRgtTUzke9HGDDKgSZCqvTnrQxw2mpvzxERERGQu/hasRNNALN15ww/3Hzu29L+Pl1URERA0Bb3ZXg6CBXih/qQ1+S/odRfcfwsbBCp0Cm3MGhoiIqAFgiHkCU1M5uvVpYewyiIiI6DGcUiAiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoghIiIiSTJIiFm/fj08PT1haWmJgIAAnDx5stq+cXFxkMlkGoulpaUhyiQiIiIJ0XuI2bZtGyIiIjB//nycPn0anTt3RmhoKG7fvl3tNgqFAtnZ2erl+vXr+i6TiIiIJEbvISYmJgbh4eEYM2YM2rdvjw0bNsDa2hqxsbHVbiOTyeDq6qpeXFxc9F0mERERSYxeQ0xpaSmSk5MREhLy3zeUyxESEoKkpKRqtysqKkLLli3h4eGBIUOG4Pz58/osk4iIiCRIryHm7t27qKioqDKT4uLigpycHK3beHt7IzY2Ft9//z2+/vprqFQqBAUF4ffff9fav6SkBEqlUmMhIiKixq/BXZ0UGBiIkSNHokuXLujbty927NgBJycnfP7551r7R0dHw87OTr14eHgYuGIiIiIyBr2GGEdHR5iYmCA3N1ejPTc3F66urrXah5mZGbp27YqMjAyt62fPno2CggL1cuPGjaeum4iIiBo+vYYYc3Nz+Pv7IzExUd2mUqmQmJiIwMDAWu2joqICZ8+ehZubm9b1FhYWUCgUGgsRERE1fqb6foOIiAiMGjUK3bt3R48ePbBmzRoUFxdjzJgxAICRI0eiWbNmiI6OBgAsXLgQPXv2RNu2bZGfn48VK1bg+vXrGD9+vL5LJSIiIgnRe4gZOnQo7ty5g3nz5iEnJwddunRBQkKC+mTfrKwsyOX/nRDKy8tDeHg4cnJy0KRJE/j7++P48eNo3769vkslIiIiCZEJIYSxi9AlpVIJOzs7FBQU8NASERFRHUjtO7TBXZ30LOnXrx+mTZtm7DKIiIgkiSGGiIiIJIkhhoiIiCSJIcbIysvLMWXKFNjZ2cHR0RFz585F5WlKX331Fbp37w5bW1u4urpi2LBhGg/OPHz4MGQyGRITE9G9e3dYW1sjKCgI6enp6j6ZmZkYMmQIXFxcYGNjg+effx4HDhzQqMHT0xNLlizB2LFjYWtrixYtWmDjxo0afWbNmoV27drB2toarVu3xty5c1FWVqbHnwwREVHNGGKMbPPmzTA1NcXJkyfx8ccfIyYmBl988QUAoKysDIsWLcKZM2fw3Xff4dq1axg9enSVfURFRWHVqlU4deoUTE1NMXbsWPW6oqIiDBw4EImJiUhJScGAAQMQFhaGrKwsjX2sWrUK3bt3R0pKCiZNmoS///3vGmHI1tYWcXFxuHDhAj7++GNs2rQJq1ev1s8PhYiIqDZEI1NQUCAAiIKCAmOX8kR9+/YVvr6+QqVSqdtmzZolfH19tfb/9ddfBQBRWFgohBDi0KFDAoA4cOCAus+ePXsEAPHw4cNq37dDhw5i3bp16tctW7YUf/vb39SvVSqVcHZ2Fp999lm1+1ixYoXw9/d/8iCJiEgypPQdKoQQnIkxsp49e0Imk6lfBwYG4vLly6ioqEBycjLCwsLQokUL2Nraom/fvgBQZRalU6dO6j9X3tm48rBTUVERZsyYAV9fX9jb28PGxgZpaWk17kMmk8HV1VXj0NW2bdvQq1cvuLq6wsbGBnPmzKmyDyIiIkNiiGmg/vjjD4SGhkKhUGDLli349ddfsXPnTgBAaWmpRl8zMzP1nysDkUqlAgDMmDEDO3fuxJIlS3DkyBGkpqaiY8eONe6jcj+V+0hKSsLw4cMxcOBA7N69GykpKYiKiqqyDyIiIkPS+x17qWYnTpzQeP3LL7/Ay8sLFy9exL1797B06VL1k7lPnTpV5/0fO3YMo0ePxmuvvQbg0czMtWvX6rSP48ePo2XLloiKilK3Xb9+vc61EBER6RJnYnRMparAjfO/Ie3YT7hx/jeoVBU19s/KykJERATS09PxzTffYN26dZg6dSpatGgBc3NzrFu3DleuXMGuXbuwaNGiOtfj5eWFHTt2IDU1FWfOnMGwYcPUMyx12UdWVhbi4+ORmZmJtWvXqmeFiIiIjIUzMTp0+cRxHIzbiKL7d9VtNg6OeHH0BHgFBGndZuTIkXj48CF69OgBExMTTJ06FRMmTIBMJkNcXBw++OADrF27Ft26dcPKlSvxyiuv1KmmmJgYjB07FkFBQXB0dMSsWbOgVCrrtI9XXnkF06dPx5QpU1BSUoJBgwZh7ty5WLBgQZ32Q0REpEt8dpKOXD5xHLtillS7/pWID6oNMkRERA0Bn530DFKpKnAwbmONfQ5t3vjEQ0tERERUewwxOnAz7bzGISRtCu/dxc208waqiIiIqPFjiNGBovw8nfYjIiKiJ2OI0QEb+yY67UdERERPxhCjA818O8DGwbHGPrZNHdHMt4OBKiIiImr8GGJ0QC43wYujJ9TYp/+oCZDLTQxUERERUePHEKMjXgFBeCXigyozMrZNHXl5NRERkR7wZnc65BUQhDbPBzy6Wik/Dzb2TdDMtwNnYIiIiPSAIUbH5HITeHTo9OSORERE9FR4OImIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIGrx+/fph2rRpxi6DiBoYhhgiIiKSJIYYIiIikiSGGCJqUIqLizFy5EjY2NjAzc0Nq1at0lifl5eHkSNHokmTJrC2tsbLL7+My5cva/TZtGkTPDw8YG1tjddeew0xMTGwt7c34CiIyBAYYoioQXn//ffx008/4fvvv8e+fftw+PBhnD59Wr1+9OjROHXqFHbt2oWkpCQIITBw4ECUlZUBAI4dO4aJEydi6tSpSE1Nxf/8z/9g8eLFxhoOEemRTAghjF2ELimVStjZ2aGgoAAKhcLY5RBRHRQVFaFp06b4+uuv8Ze//AUAcP/+fTRv3hwTJkzA5MmT0a5dOxw7dgxBQUEAgHv37sHDwwObN2/GX/7yF7z55psoKirC7t271fv929/+ht27dyM/P98YwyKSDKl9h3ImhogajMzMTJSWliIgIEDd5uDgAG9vbwBAWloaTE1NNdY3bdoU3t7eSEtLAwCkp6ejR48eGvt9/DURNQ4MMURERCRJDDFE1GC0adMGZmZmOHHihLotLy8Ply5dAgD4+vqivLxcY/29e/eQnp6O9u3bAwC8vb3x66+/auz38ddE1DiYGrsAIno2iIoKPDiVjPI7d2Dq5ATr7v6QmZho9LGxscG4cePw/vvvo2nTpnB2dkZUVBTk8kf/3vLy8sKQIUMQHh6Ozz//HLa2toiMjESzZs0wZMgQAMA777yDF154ATExMQgLC8PBgwfxww8/QCaTGXzMRKRfnIkhIr1T7tuHjOAQZI0ahVszZiBr1ChkBIdAuW9flb4rVqxAnz59EBYWhpCQEPTu3Rv+/v7q9V9++SX8/f0xePBgBAYGQgiBvXv3wszMDADQq1cvbNiwATExMejcuTMSEhIwffp0WFpaGmy8RGQYvDqJiPRKuW8fbk6dBjz+UfOfmZFmH6+B4qWX9FpDeHg4Ll68iCNHjuj1fYikTmrfoZyJISK9ERUVyF0SXTXAAOq23CXREBUVOn3flStX4syZM8jIyMC6deuwefNmjBo1SqfvQUTGx3NiiEhvHpxKRnlOTvUdhEB5Tg4enErGcwG6uwz65MmTWL58OQoLC9G6dWusXbsW48eP19n+iahhYIghIr0pv3NHp/1q69tvv9Xp/oioYeLhJCLSG1MnJ532IyL6M4OEmPXr18PT0xOWlpYICAjAyZMna+y/fft2+Pj4wNLSEh07dsTevXsNUSYR6Zh1d3+YurqqT+KtQiaDqasrrLv7a19PRFQDvYeYbdu2ISIiAvPnz8fp06fRuXNnhIaG4vbt21r7Hz9+HG+99RbGjRuHlJQUvPrqq3j11Vdx7tw5fZdKRDomMzGBywez//PisSDzn9cuH8yucr8YIqLa0Psl1gEBAXj++efxySefAABUKhU8PDzwzjvvIDIyskr/oUOHori4WOPhbT179kSXLl2wYcOGJ76f1C4PI3oWKPftQ+6SaI2TfE1dXeHywWy9X15NRLUnte9QvZ7YW1paiuTkZMyePVvdJpfLERISgqSkJK3bJCUlISIiQqMtNDQU3333nT5LJSI9Urz0EmyDg594x14iorrQa4i5e/cuKioq4OLiotHu4uKCixcvat0mJydHa/+cai7TLCkpQUlJifq1Uql8yqqJSB9kJiY6vYyaiEjyVydFR0fDzs5OvXh4eBi7JCIiIjIAvYYYR0dHmJiYIDc3V6M9NzcXrq6uWrdxdXWtU//Zs2ejoKBAvdy4cUM3xRMREVGDptcQY25uDn9/fyQmJqrbVCoVEhMTERgYqHWbwMBAjf4AsH///mr7W1hYQKFQaCxERETU+On9jr0REREYNWoUunfvjh49emDNmjUoLi7GmDFjAAAjR45Es2bNEB0dDQCYOnUq+vbti1WrVmHQoEGIj4/HqVOnsHHjRn2XSkRERBKi9xAzdOhQ3LlzB/PmzUNOTg66dOmChIQE9cm7WVlZkMv/OyEUFBSErVu3Ys6cOfjggw/g5eWF7777Dn5+fvoulYiIiCRE7/eJMTSpXeNORETUUEjtO1TyVycRERHRs4khhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIJIkhhoiIiCSJIYaIiIgkiSGGiIiIqhUXFwd7e/sG+T4MMURERFStoUOH4tKlS8YuQytTYxdAREREDZeVlRWsrKyMXYZWnIkhIiJqxBISEtC7d2/Y29ujadOmGDx4MDIzMwEA165dg0wmw44dO9C/f3+4uroCAE6ePKne/vHDPAsWLECXLl0QGxuLFi1awMbGBpMmTUJFRQWWL18OV1dXODs7Y/HixRp1xMTEoGPHjnjuuefg4eGBSZMmoaio6KnGxhBDRETUiBUXFyMiIgKnTp1CYmIi5HI5XnvtNahUKnWfqKgozJgxA0ePHgUAjBs3DuXl5dXuMzMzEz/88AMSEhLwzTff4B//+AcGDRqE33//HT/99BOWLVuGOXPm4MSJE+pt5HI51q5di/Pnz2Pz5s04ePAgZs6c+VRj4+EkIiKiRuyNN97QeB0bGwsnJydcuHABNjY2AIAZM2Zg0KBBUCqVAICsrCxkZGTAx8dH6z5VKhViY2Nha2uL9u3bo3///khPT8fevXshl8vh7e2NZcuW4dChQwgICAAATJs2Tb29p6cnPvroI0ycOBGffvppvcfGmRgiIqJG7PLly3jrrbfQunVrKBQKeHp6AngUVCp16tSpyna3b9+udp+enp6wtbVVv3ZxcUH79u0hl8s12v68jwMHDiA4OBjNmjWDra0tRowYgXv37uHBgwf1HhtDDBERUSMWFhaG+/fvY9OmTThx4oT6EE9paam6j5mZWZXt/ny46XGP95fJZFrbKvdx7do1DB48GJ06dcL//d//ITk5GevXr69SR13pLcTcv38fw4cPh0KhgL29PcaNG/fEE3j69esHmUymsUycOFFfJRIREUmTqgK4egQ4+69H/1VVaO127949pKenY86cOQgODoavry/y8vIMXCyQnJwMlUqFVatWoWfPnmjXrh1u3br11PvV2zkxw4cPR3Z2Nvbv34+ysjKMGTMGEyZMwNatW2vcLjw8HAsXLlS/tra21leJRERE0nNhF5AwC1D+KQQo3IEBy4D2r2h0bdKkCZo2bYqNGzfCzc0NWVlZiIyMNHDBQNu2bVFWVoZ169YhLCwMx44dw4YNG556v3qZiUlLS0NCQgK++OILBAQEoHfv3li3bh3i4+OfmLysra3h6uqqXhQKhT5KJCIikp4Lu4BvR2oGGABQZj9qv7BLo1kulyM+Ph7Jycnw8/PD9OnTsWLFCgMW/Ejnzp0RExODZcuWwc/PD1u2bEF0dPRT71cmhBA6qE9DbGws3nvvPY0pq/LyclhaWmL79u147bXXtG7Xr18/nD9/HkIIuLq6IiwsDHPnzq1xNqakpAQlJSXq10qlEh4eHigoKGAAIiKixkNVAazxqxpg1GSPZmSmnQXkJvV6C6VSCTs7O8l8h+rlcFJOTg6cnZ0138jUFA4ODsjJyal2u2HDhqFly5Zwd3fHb7/9hlmzZiE9PR07duyodpvo6Gh8+OGHOqudiIioQbp+vIYAAwACUN581K9VH4OVZUx1CjGRkZFYtmxZjX3S0tLqXcyECRPUf+7YsSPc3NwQHByMzMxMtGnTRus2s2fPRkREhPp15UwMERFRo1KUq9t+jUCdQsx7772H0aNH19indevWcHV1rXJ9eXl5Oe7fv6++pXFtVN4gJyMjo9oQY2FhAQsLi1rvk4iISJJsXHTbrxGoU4hxcnKCk5PTE/sFBgYiPz8fycnJ8Pf3BwAcPHgQKpVKHUxqIzU1FQDg5uZWlzKJiIgan5ZBj855UWYD0HY663/OiWkZZOjKjEYvVyf5+vpiwIABCA8Px8mTJ3Hs2DFMmTIFb775Jtzd3QEAN2/ehI+Pj/ohU5mZmVi0aBGSk5Nx7do17Nq1CyNHjsQLL7yg9U6CREREzxS5yaPLqAEAssdW/uf1gKX1PqlXivR2s7stW7bAx8cHwcHBGDhwIHr37o2NGzeq15eVlSE9PV19u2Fzc3McOHAAL730Enx8fPDee+/hjTfewL///W99lUhERCQt7V8B/vpPQPHYEQqF+6P2x+4T09jp5RJrY5La5WFERER1pqp4dBVSUe6jc2BaBulkBkZq36F8ijUREZHUyE2emcuoa8IHQBIREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBAREZEkMcQQERGRJDHEEBERkSQxxBARkU4tWLAAXbp0MXYZ9AxgiCEiIiJJYoghIqIqVCoVli9fjrZt28LCwgItWrTA4sWLAQCzZs1Cu3btYG1tjdatW2Pu3LkoKysDAMTFxeHDDz/EmTNnIJPJIJPJEBcXZ8SRUGNmauwCiIio4Zk9ezY2bdqE1atXo3fv3sjOzsbFixcBALa2toiLi4O7uzvOnj2L8PBw2NraYubMmRg6dCjOnTuHhIQEHDhwAABgZ2dnzKFQIyYTQghjF6FLSqUSdnZ2KCgogEKhMHY5RESSU1hYCCcnJ3zyyScYP378E/uvXLkS8fHxOHXqFIBH58R89913SE1N1XOlpGtS+w7lTAwREWlIS0tDSUkJgoODta7ftm0b1q5di8zMTBQVFaG8vFwSX3jU+PCcGCIi0mBlZVXtuqSkJAwfPhwDBw7E7t27kZKSgqioKJSWlhqwQqJHGGKIiEiDl5cXrKyskJiYWGXd8ePH0bJlS0RFRaF79+7w8vLC9evXNfqYm5ujoqLCUOXSM4yHk4iInhEVqgqcvn0adx7cgZO1E7o5d4OJ3KRKP0tLS8yaNQszZ86Eubk5evXqhTt37uD8+fPw8vJCVlYW4uPj8fzzz2PPnj3YuXOnxvaenp64evUqUlNT0bx5c9ja2sLCwsJQw6RnCE/sJSJ6Bhy4fgBLTy5F7oNcdZuLtQsie0QipGVIlf4qlQrR0dHYtGkTbt26BTc3N0ycOBGzZ8/GzJkzERsbi5KSEgwaNAg9e/bEggULkJ+fDwAoKSnB8OHDkZiYiPz8fHz55ZcYPXq0gUZKT0Nq36EMMUREjdyB6wcQcTgCApof9zLIAAAx/WK0Bhl69kjtO5TnxBARNWIVqgosPbm0SoABoG5bdnIZKlQ8h4WkhyGGiKgRO337tMYhpMcJCOQ8yMHp26cNWBWRbjDEEBE1Ynce3NFpP6KGhCGGiKgRc7J20mk/ooaEIYaIqBHr5twNLtYu6pN4HyeDDK7Wrujm3M3AlRE9PYYYIqJGzERugsgekQBQJchUvp7VY5bW+8UQNXQMMUREjVxIyxDE9IuBs7WzRruLtQsvryZJ4x17iYieASEtQ9Dfo3+t7thLJBUMMUREzwgTuQmed33e2GUQ6QwPJxEREZEkMcQQERGRJDW6w0mVj4JSKpVGroSIiEhaKr87pfJYxUYXYgoLCwEAHh4eRq6EiIhImgoLC2FnZ2fsMp6o0T3FWqVS4datW7C1tYVMpv3mTrWlVCrh4eGBGzduSOJpnk/C8TRsHE/D1ZjGAnA8DZ0xxyOEQGFhIdzd3SGXN/wzThrdTIxcLkfz5s11uk+FQtEo/mJU4ngaNo6n4WpMYwE4nobOWOORwgxMpYYfs4iIiIi0YIghIiIiSWKIqYGFhQXmz58PCwsLY5eiExxPw8bxNFyNaSwAx9PQNbbx6FOjO7GXiIiIng2ciSEiIiJJYoghIiIiSWKIISIiIkliiCEiIiJJYoh5zP379zF8+HAoFArY29tj3LhxKCoqeuJ2SUlJePHFF/Hcc89BoVDghRdewMOHDw1Qcc3qOx7g0Z0bX375ZchkMnz33Xf6LbQW6jqW+/fv45133oG3tzesrKzQokULvPvuuygoKDBg1ZrWr18PT09PWFpaIiAgACdPnqyx//bt2+Hj4wNLS0t07NgRe/fuNVClT1aXsWzatAl9+vRBkyZN0KRJE4SEhDxx7IZW199Npfj4eMhkMrz66qv6LbCO6jqe/Px8TJ48GW5ubrCwsEC7du0k+/8bAKxZs0b9d9/DwwPTp0/HH3/8YaBqa/bzzz8jLCwM7u7utf58PXz4MLp16wYLCwu0bdsWcXFxeq9TEgRpGDBggOjcubP45ZdfxJEjR0Tbtm3FW2+9VeM2x48fFwqFQkRHR4tz586Jixcvim3btok//vjDQFVXrz7jqRQTEyNefvllAUDs3LlTv4XWQl3HcvbsWfH666+LXbt2iYyMDJGYmCi8vLzEG2+8YcCq/ys+Pl6Ym5uL2NhYcf78eREeHi7s7e1Fbm6u1v7Hjh0TJiYmYvny5eLChQtizpw5wszMTJw9e9bAlVdV17EMGzZMrF+/XqSkpIi0tDQxevRoYWdnJ37//XcDV65dXcdT6erVq6JZs2aiT58+YsiQIYYpthbqOp6SkhLRvXt3MXDgQHH06FFx9epVcfjwYZGammrgyrWr63i2bNkiLCwsxJYtW8TVq1fFjz/+KNzc3MT06dMNXLl2e/fuFVFRUWLHjh21+ny9cuWKsLa2FhEREeLChQti3bp1wsTERCQkJBim4AaMIeZPLly4IACIX3/9Vd32ww8/CJlMJm7evFntdgEBAWLOnDmGKLFO6jseIYRISUkRzZo1E9nZ2Q0ixDzNWP7s22+/Febm5qKsrEwfZdaoR48eYvLkyerXFRUVwt3dXURHR2vt/9e//lUMGjRIoy0gIEC8/fbbeq2zNuo6lseVl5cLW1tbsXnzZn2VWCf1GU95ebkICgoSX3zxhRg1alSDCjF1Hc9nn30mWrduLUpLSw1VYp3UdTyTJ08WL774okZbRESE6NWrl17rrI/afL7OnDlTdOjQQaNt6NChIjQ0VI+VSQMPJ/1JUlIS7O3t0b17d3VbSEgI5HI5Tpw4oXWb27dv48SJE3B2dkZQUBBcXFzQt29fHD161FBlV6s+4wGABw8eYNiwYVi/fj1cXV0NUeoT1XcsjysoKIBCoYCpqWEfG1ZaWork5GSEhISo2+RyOUJCQpCUlKR1m6SkJI3+ABAaGlptf0Opz1ge9+DBA5SVlcHBwUFfZdZafcezcOFCODs7Y9y4cYYos9bqM55du3YhMDAQkydPhouLC/z8/LBkyRJUVFQYquxq1Wc8QUFBSE5OVh9yunLlCvbu3YuBAwcapGZda6ifBQ1Bo3sA5NPIycmBs7OzRpupqSkcHByQk5OjdZsrV64AABYsWICVK1eiS5cu+Oc//4ng4GCcO3cOXl5eeq+7OvUZDwBMnz4dQUFBGDJkiL5LrLX6juXP7t69i0WLFmHChAn6KPGJ711RUQEXFxeNdhcXF1y8eFHrNjk5OVr713a8+lKfsTxu1qxZcHd3r/LBbAz1Gc/Ro0fxj3/8A6mpqQaosG7qM54rV67g4MGDGD58OPbu3YuMjAxMmjQJZWVlmD9/viHKrlZ9xjNs2DDcvXsXvXv3hhAC5eXlmDhxIj744ANDlKxz1X0WKJVKPHz4EFZWVkaqzPieiZmYyMhIyGSyGpfafvg+TqVSAQDefvttjBkzBl27dsXq1avh7e2N2NhYXQ5DTZ/j2bVrFw4ePIg1a9botuhq6HMsf6ZUKjFo0CC0b98eCxYsePrCqd6WLl2K+Ph47Ny5E5aWlsYup84KCwsxYsQIbNq0CY6OjsYuRydUKhWcnZ2xceNG+Pv7Y+jQoYiKisKGDRuMXVq9HD58GEuWLMGnn36K06dPY8eOHdizZw8WLVpk7NJIx56JmZj33nsPo0ePrrFP69at4erqitu3b2u0l5eX4/79+9UeVnFzcwMAtG/fXqPd19cXWVlZ9S+6Bvocz8GDB5GZmQl7e3uN9jfeeAN9+vTB4cOHn6LyqvQ5lkqFhYUYMGAAbG1tsXPnTpiZmT1t2XXm6OgIExMT5ObmarTn5uZWW7+rq2ud+htKfcZSaeXKlVi6dCkOHDiATp066bPMWqvreDIzM3Ht2jWEhYWp2yr/MWNqaor09HS0adNGv0XXoD6/Hzc3N5iZmcHExETd5uvri5ycHJSWlsLc3FyvNdekPuOZO3cuRowYgfHjxwMAOnbsiOLiYkyYMAFRUVGQy6X17/fqPgsUCsUzPQsDPCMhxsnJCU5OTk/sFxgYiPz8fCQnJ8Pf3x/Aoy91lUqFgIAArdt4enrC3d0d6enpGu2XLl3Cyy+//PTFa6HP8URGRqr/4lfq2LEjVq9erfGhrSv6HAvwaAYmNDQUFhYW2LVrl9H+5W9ubg5/f38kJiaqL8VVqVRITEzElClTtG4TGBiIxMRETJs2Td22f/9+BAYGGqDi6tVnLACwfPlyLF68GD/++KPGuU3GVtfx+Pj44OzZsxptc+bMQWFhIT7++GN4eHgYouxq1ef306tXL2zduhUqlUr9BX/p0iW4ubkZNcAA9RvPgwcPqgSVyoAmJPi4wMDAwCqXuzeEz4IGwdhnFjc0AwYMEF27dhUnTpwQR48eFV5eXhqX8f7+++/C29tbnDhxQt22evVqoVAoxPbt28Xly5fFnDlzhKWlpcjIyDDGEDTUZzyPQwO4OkmIuo+loKBABAQEiI4dO4qMjAyRnZ2tXsrLyw1ef3x8vLCwsBBxcXHiwoULYsKECcLe3l7k5OQIIYQYMWKEiIyMVPc/duyYMDU1FStXrhRpaWli/vz5DeoS67qMZenSpcLc3Fz861//0vg9FBYWGmsIGuo6nsc1tKuT6jqerKwsYWtrK6ZMmSLS09PF7t27hbOzs/joo4+MNQQNdR3P/Pnzha2trfjmm2/ElStXxL59+0SbNm3EX//6V2MNQUNhYaFISUkRKSkpAoCIiYkRKSkp4vr160IIISIjI8WIESPU/SsvsX7//fdFWlqaWL9+PS+x/g+GmMfcu3dPvPXWW8LGxkYoFAoxZswYjQ/aq1evCgDi0KFDGttFR0eL5s2bC2traxEYGCiOHDli4Mq1q+94/qyhhJi6juXQoUMCgNbl6tWrRhnDunXrRIsWLYS5ubno0aOH+OWXX9Tr+vbtK0aNGqXR/9tvvxXt2rUT5ubmokOHDmLPnj0Grrh6dRlLy5Yttf4e5s+fb/jCq1HX382fNbQQI0Tdx3P8+HEREBAgLCwsROvWrcXixYuNEvarU5fxlJWViQULFog2bdoIS0tL4eHhISZNmiTy8vIMX7gW1X02VY5h1KhRom/fvlW26dKlizA3NxetW7cWX375pcHrbohkQkhwbo2IiIieedI6u4mIiIjoPxhiiIiISJIYYoiIiEiSGGKIiIhIkhhiiIiISJIYYoiIiEiSGGKIiIhIkhhiiIiISJIYYoiIiEiSGGKIiIhIkhhiiIiISJIYYoiIiEiS/h+4BAcQF5ia9gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'cat', 'dog', 'apple', 'banana', '<UNK>']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.9996472086687568\n",
            "cat vs. animal:  0.8659760114861905\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.9996472086687569\n",
            "cat vs. animal:  0.8659760114861905\n",
            "cat vs. cat:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
