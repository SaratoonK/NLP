{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "## Word2Vec (Negative Sampling)\n",
        "\n",
        "Let's work on negative-sampling based implementation of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = [\"apple banana ice\", \"banana orange fruit\", \"orange ice fruit\", \"orange grapes fruit\", \"banana ice fruit\", \"grapes fruit ice\",\n",
        "                 \"dog cat animal\", \"cat monkey animal\", \"monkey dog animal\", \"conda dog animal\", \"monkey dog conda\", \"monkey conda animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'ice', 'banana', 'orange', 'fruit', 'orange', 'ice', 'fruit', 'orange', 'grapes', 'fruit', 'banana', 'ice', 'fruit', 'grapes', 'fruit', 'ice', 'dog', 'cat', 'animal', 'cat', 'monkey', 'animal', 'monkey', 'dog', 'animal', 'conda', 'dog', 'animal', 'monkey', 'dog', 'conda', 'monkey', 'conda', 'animal']\n"
          ]
        }
      ],
      "source": [
        "#get word sequences\n",
        "word_sequence = \" \".join(sentences).split()\n",
        "print(word_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['animal', 'monkey', 'grapes', 'conda', 'orange', 'cat', 'fruit', 'banana', 'apple', 'ice', 'dog']\n"
          ]
        }
      ],
      "source": [
        "#get unique words\n",
        "word_list = \" \".join(sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "print(word_list)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'animal': 0, 'monkey': 1, 'grapes': 2, 'conda': 3, 'orange': 4, 'cat': 5, 'fruit': 6, 'banana': 7, 'apple': 8, 'ice': 9, 'dog': 10}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "print(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(word_list)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'fruit'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_sequence[16]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Make our skipgram batch loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence):\n",
        "    \n",
        "    # Make skip gram of one size window\n",
        "    skip_grams = []\n",
        "    # loop each word sequence\n",
        "    # we starts from 1 because 0 has no context\n",
        "    # we stop at second last for the same reason\n",
        "    for i in range(1, len(word_sequence) - 1):\n",
        "        target = word_dict[word_sequence[i]]  #banana is 6 so return 6        \n",
        "        context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]] #left of banana is apple; right is fruit, so context is [4, 2]\n",
        "        for w in context:\n",
        "            skip_grams.append([target, w]) #e.g., [6, 4], [6, 2], so on... (target, context)\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
        "    \n",
        "    #make input and labels as one-hot encoding\n",
        "    #we cannot train using taking integer as input...\n",
        "    for i in random_index:\n",
        "        random_inputs.append(np.eye(voc_size)[skip_grams[i][0]])  # target,e g., [0, 0, 0, 0, 0, 1, 0, 0]\n",
        "        random_labels.append(skip_grams[i][1])  # context word, e.g., 3\n",
        "\n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "Target:  [2 6]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch = random_batch(batch_size, word_sequence)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Word2Vec(nn.Module):\n",
        "    def __init__(self, embedding_size):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        # W and WT is not Traspose relationship\n",
        "        self.W = nn.Linear(voc_size, embedding_size, bias=False) # voc_size > embedding_size Weight\n",
        "        self.WT = nn.Linear(embedding_size, voc_size, bias=False) # embedding_size > voc_size Weight\n",
        "\n",
        "    def forward(self, X):\n",
        "        # X : [batch_size, voc_size]\n",
        "        hidden_layer = self.W(X) # hidden_layer : [batch_size, embedding_size]\n",
        "        output_layer = self.WT(hidden_layer) # output_layer : [batch_size, voc_size]\n",
        "        return output_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_size = 2 #so we can later plot\n",
        "model = Word2Vec(embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 cost = 2.395988\n",
            "Epoch: 2000 cost = 1.763380\n",
            "Epoch: 3000 cost = 1.707680\n",
            "Epoch: 4000 cost = 1.245237\n",
            "Epoch: 5000 cost = 1.815973\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    input_batch, target_batch = random_batch(batch_size, word_sequence)\n",
        "    input_batch = torch.Tensor(input_batch)\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_batch)\n",
        "\n",
        "    # output : [batch_size, voc_size], target_batch : [batch_size] (LongTensor, not one-hot)\n",
        "    loss = criterion(output, target_batch)\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 11])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W, WT = model.parameters()\n",
        "W.shape #embedding (x, y), vocab (unique vocabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.39345237612724304"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#x embedding of the first vocab\n",
        "W[0][1].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.3749170303344727"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#y embedding of the first vocab\n",
        "W[1][1].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, label in enumerate(word_list): #loop each unique vocab\n",
        "    W, WT = model.parameters()\n",
        "    x, y = W[0][i].item(), W[1][i].item()\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['animal',\n",
              " 'monkey',\n",
              " 'grapes',\n",
              " 'conda',\n",
              " 'orange',\n",
              " 'cat',\n",
              " 'fruit',\n",
              " 'banana',\n",
              " 'apple',\n",
              " 'ice',\n",
              " 'dog']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "\n",
        "#embedding = x, y, vocab = 0\n",
        "first      = [W[0][0].item(), W[1][0].item()]\n",
        "second     = [W[0][1].item(), W[1][1].item()]\n",
        "third      = [W[0][2].item(), W[1][2].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "animal vs. monkey:  0.9907741916907582\n",
            "animal vs. grapes: -0.8447612339937328\n",
            "animal vs. animal:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"{word_list[0]} vs. {word_list[1]}: \",   cos_sim(first, second))\n",
        "print(f\"{word_list[0]} vs. {word_list[2]}:\",    cos_sim(second, third))\n",
        "print(f\"{word_list[0]} vs. {word_list[0]}: \",   cos_sim(first, first))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "animal vs. monkey:  0.9907741916907584\n",
            "animal vs. grapes: -0.8447612339937329\n",
            "animal vs. animal:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"{word_list[0]} vs. {word_list[1]}: \",   cos_sim(first, second))\n",
        "print(f\"{word_list[0]} vs. {word_list[2]}:\",    cos_sim(second, third))\n",
        "print(f\"{word_list[0]} vs. {word_list[0]}: \",   cos_sim(first, first))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6 (default, Nov 17 2020, 08:01:36) \n[Clang 12.0.0 (clang-1200.0.32.21)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
