{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "## Word2Vec (Negative Sampling)\n",
        "\n",
        "Let's work on negative-sampling based implementation of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'apple', 'cat', 'banana', 'dog']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fruit': 0, 'animal': 1, 'apple': 2, 'cat': 3, 'banana': 4, 'dog': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'apple', 'cat', 'banana', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence):\n",
        "    \n",
        "    # Make skip gram of one size window\n",
        "    skip_grams = []\n",
        "    # loop each word sequence\n",
        "    # we starts from 1 because 0 has no context\n",
        "    # we stop at second last for the same reason\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[0]\n",
            " [3]]\n",
            "Target:  [[2]\n",
            " [5]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "print(\"Input: \",  input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2, 1), (2, 1))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Negative Sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unigram distribution\n",
        "\n",
        "$$P(w)=U(w)^{3/4}/Z$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "Z = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter(flatten(corpus))\n",
        "num_total_words = sum([c for w, c in word_count.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count[',']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "unigram_table = []\n",
        "\n",
        "for vo in vocab:\n",
        "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'fruit': 260,\n",
              "         'animal': 260,\n",
              "         'apple': 260,\n",
              "         'cat': 260,\n",
              "         'banana': 260,\n",
              "         'dog': 260})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(unigram_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Negative Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.size(0)\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):\n",
        "        nsample = []\n",
        "        target_index = targets[i].item()\n",
        "        while len(nsample) < k: # num of sampling\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
        "    \n",
        "    return torch.cat(neg_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_batch  = torch.Tensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 5, 0],\n",
              "        [3, 0, 0]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_neg = 3\n",
        "negative_sampling(target_batch, unigram_table, num_neg)\n",
        "\n",
        "#{'grapes': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'ice': 4, 'orange': 5, 'dog': 6, 'monkey': 7, 'conda': 8, 'fruit': 9, 'banana': 10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "                    \n",
        "    def forward(self, center_words, target_words, negative_words):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
        "        \n",
        "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
        "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
        "        \n",
        "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
        "                \n",
        "        return -torch.mean(loss)\n",
        "    \n",
        "    def prediction(self, inputs):\n",
        "        embeds = self.embedding_v(inputs)\n",
        "        \n",
        "        return embeds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 2 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
        "num_neg        = 10 # num of negative sampling\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 7.734130 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 5.816563 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 2.958702 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 3.172576 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 3.226354 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "    \n",
        "    #input_batch: [batch_size, 1]\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    \n",
        "    #target_batch: [batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "    \n",
        "    #negs_batch:   [batch_size, num_neg]\n",
        "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    loss = model(input_batch, target_batch, negs_batch)\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'apple', 'cat', 'banana', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-1.1898,  1.8828]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[ 1.0029, -1.7315]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0757, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'animal', 'apple', 'cat', 'banana', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.178255229122321\n",
            "cat vs. animal:  0.9825088882001791\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.17825522912232095\n",
            "cat vs. animal:  0.9825088882001791\n",
            "cat vs. cat:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
