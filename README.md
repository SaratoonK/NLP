# NLP / NLU - Natural Language Processing / Natural Language Understanding

This is the repository for the Natural Language Processing / Natural Language Understanding at Asian Institute of Technology.

I would also like to give credits to several githubs/web resources that I have revised to create this:

- https://web.stanford.edu/class/cs224n/
- https://github.com/bentrevett
- https://github.com/graykode/nlp-tutorial
- https://github.com/mhagiwara/100-nlp-papers
- https://github.com/keon/awesome-nlp
- https://github.com/sebastianruder/NLP-progress

I would also like to thank students who have contributed:

- Pranisaa Charnparttarvanit
- Chanapa Pananookooln

## Course Outline

The course is structured into 3 big components (and 1 small component):

### 1. Natural Language Understanding
Focus on understanding basic knowledge
  - The whole process of understanding - tokenization, lemming, stemming, POS, etc.
  - Dependency Parsing
  - Constituent Parsing
  - NLP Tasks

### 2. Word Embeddings
Focus on understanding how word representations work
  - Word2Vec
  - GloVe
  - FastText
  - ELMo
  - Other rising stars
  
### 3. Neural Network
Focus on understanding common neural network architecture for NLP
  - Recurrent Neural Network
  - Long Short-Term Memory
  - Long Short-Term Memory with Attention
  - Long Short-Term Memory with Multiheaded Attention
  - Seq2seq (Encoder-Decoder)
  - Seq2seq (Transformers)

### 4. Contemporary Topics
Ask students to share their knowledge after reading assigned papers
  - For list of good conference, look here http://chaklam.com/node/32 

## Grade Criteria

The course has the following grade criteria:
1. Assignment (50%)
    - There will be a total of 6 coding assignments + 1 paper presentation assignment
    -  A1: Getting Started (5%)
    -  A2: Word2Vec (8%)
    -  A3: Dependency Parsing (8%)
    -  A4: Bidirectional LSTM with Attention for Classification from Scratch (8%)
    -  A5: Encoder-Decoder with Attention for Seq2Seq from Scratch (8%)
    -  A6: Transformer (Attention only) (8%)
    -  A7: Paper Reading (5%)  
2. Final Project (45%)
    - Project focusing on one of the typical NLP tasks, e.g., question-answering, image captioning, text summarization, etc.
    - Main criteria focuses on reasonable methodologies, processes, and accuracy.
    - Submission deliverables:  (1) python file (e.g., notebook, .py), (2) Report in IEEE format (introduction, related work, methodology, results, discussion), (3) presentation file (e.g., .pdf, .ppt)
3. Participation (5%)
    - Regularly attending the class, and answering in the class
    - Any act that would improve the class, e.g., suggesting some potential bugs or typos
